{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DIMENSIONALITY REDUCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Many machine learning problems involve thousands or even millions of\n",
    " features for each training instance. Not only do all these features make\n",
    " training extremely slow, but they can also make it much harder to find a\n",
    " good solution, as you will see. This problem is often referred to as the curse\n",
    " of dimensionality.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***WARNING:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing dimensionality does cause some information loss, just like compressing an\n",
    " image to JPEG can degrade its quality, so even though it will speed up training, it may\n",
    " make your system perform slightly worse. It also makes your pipelines a bit more\n",
    " complex and thus harder to maintain. Therefore, I recommend you first try to train your\n",
    " system with the original data before considering using dimensionality reduction. In\n",
    " some cases, reducing the dimensionality of the training data may filter out some noise\n",
    " and unnecessary details and thus result in higher performance, but in general it won’t; it\n",
    " will just speed up training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from speeding up training, dimensionality reduction is also extremely\n",
    " useful for data visualization. Reducing the number of dimensions down to\n",
    " two (or three) makes it possible to plot a condensed view of a high\n",
    "dimensional training set on a graph and often gain some important insights\n",
    " by visually detecting patterns, such as clusters. Moreover, data visualization\n",
    " is essential to communicate your conclusions to people who are not data\n",
    " scientists—in particular, decision makers who will use your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this chapter we will first discuss the curse of dimensionality and get a\n",
    " sense of what goes on in high-dimensional space. Then we will consider the\n",
    " two main approaches to dimensionality reduction (***projection*** and ***manifold***\n",
    " learning), and we will go through three of the most popular dimensionality\n",
    " reduction techniques: ***PCA***, ***random*** ***projection***, and ***locally*** ***linear***\n",
    " ***embedding*** ***(LLE)***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Curse of Dimensionality**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are so used to living in three dimensions  that our intuition fails us\n",
    " when we try to imagine a high-dimensional space. Even a basic 4D\n",
    " hypercube is incredibly hard to picture in our minds, let\n",
    " alone a 200-dimensional ellipsoid bent in a 1,000-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It turns out that many things behave very differently in high-dimensional\n",
    " space. For example, if you pick a random point in a unit square (a 1 × 1\n",
    " square), it will have only about a 0.4% chance of being located less than\n",
    "0.001 from a border (in other words, it is very unlikely that a random point\n",
    " will be “extreme” along any dimension). But in a 10,000-dimensional unit\n",
    " hypercube, this probability is greater than 99.999999%. Most points in a\n",
    " high-dimensional hypercube are very close to the border. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " high-dimensional datasets are at risk of being very sparse: most\n",
    " training instances are likely to be far away from each other. This also means\n",
    " that a new instance will likely be far away from any training instance,\n",
    " making predictions much less reliable than in lower dimensions, since they\n",
    " will be based on much larger extrapolations. In short, the more dimensions\n",
    " the training set has, the greater the risk of overfitting it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In theory, one solution to the curse of dimensionality could be to increase\n",
    " the size of the training set to reach a sufficient density of training instances.\n",
    " Unfortunately, in practice, the number of training instances required to\n",
    " reach a given density grows exponentially with the number of dimensions.\n",
    " With just 100 features—significantly fewer than in the MNIST problem—\n",
    " all ranging from 0 to 1, you would need more training instances than atoms\n",
    " in the observable universe in order for training instances to be within 0.1 of\n",
    " each other on average, assuming they were spread out uniformly across all\n",
    " dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main Approches for Dimensionality Reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into specific dimensionality reduction algorithms, let’s take\n",
    " a look at the two main approaches to reducing dimensionality: projection\n",
    " and manifold learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Projection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In most real-world problems, training instances are not spread out\n",
    " uniformly across all dimensions. Many features are almost constant, while\n",
    " others are highly correlated (as discussed earlier for MNIST). As a result,\n",
    " all training instances lie within (or close to) a much lower-dimensional\n",
    " subspace of the high-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### ***Consider an Example from the Book***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Manifold Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, projection is not always the best approach to dimensionality\n",
    " reduction. In many cases the subspace may twist and turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### ***Consider a Swiss roll Example from the Book***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many dimensionality reduction algorithms work by modeling the manifold\n",
    " on which the training instances lie; this is called manifold learning. It relies\n",
    " on the manifold assumption, also called the manifold hypothesis, which\n",
    " holds that most real-world high-dimensional datasets lie close to a much\n",
    " lower-dimensional manifold. This assumption is very often empirically\n",
    " observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The manifold assumption is often accompanied by another implicit\n",
    " assumption: that the task at hand (e.g., classification or regression) will be\n",
    " simpler if expressed in the lower-dimensional space of the manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In short, reducing the dimensionality of your training set before training a\n",
    " model will usually speed up training, but it may not always lead to a better\n",
    " or simpler solution; it all depends on the dataset.\n",
    " Hopefully you now have a good sense of what the curse of dimensionality\n",
    " is and how dimensionality reduction algorithms can fight it, especially\n",
    " when the manifold assumption holds. The rest of this chapter will go\n",
    " through some of the most popular algorithms for dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Principal component analysis* (PCA) is by far the most popular dimensionality reduction algorithm. First it identify the hyperplane that lies closest to the data, and then it projects the data onto it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preserving the Variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can project the training set onto a lower-dimensional\n",
    " hyperplane, you first need to choose the right hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It seems reasonable to select the axis that preserves the maximum amount\n",
    " of variance, as it will most likely lose less information than the other\n",
    " projections. Another way to justify this choice is that it is the axis that\n",
    " minimizes the mean squared distance between the original dataset and its\n",
    " projection onto that axis. This is the rather simple idea behind PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Principal Components**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " PCA identifies the axis that accounts for the largest amount of variance in\n",
    " the training set. If it were a higher-dimensional dataset, PCA would also find a third\n",
    " axis, orthogonal to both previous axes, and a fourth, a fifth, and so on—as\n",
    " many axes as the number of dimensions in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The i<sub>th</sub> axis is called the i<sub>th</sub> *principal component* (PC) of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **NOTE:**\n",
    " For each principal component, PCA finds a zero-centered unit vector pointing in the\n",
    " direction of the PC. Since two opposing unit vectors lie on the same axis, the direction\n",
    " of the unit vectors returned by PCA is not stable: if you perturb the training set slightly\n",
    " and run PCA again, the unit vectors may point in the opposite direction as the original\n",
    " vectors. However, they will generally still lie on the same axes. In some cases, a pair of\n",
    " unit vectors may even rotate or swap (if the variances along these two axes are very\n",
    " close), but the plane they define will generally remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So how can you find the principal components of a training set? Luckily,\n",
    " there is a standard matrix factorization technique called ***singular value decomposition*** (SVD) that can decompose the training set matrix X into the\n",
    " matrix multiplication of three matrices **U Σ V<sup>T</sup>**, Where **V** contains the unit vector that define all the principal components that you ar looking for, as shown In the Equation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ***Equation for Principal Components Matrix***\n",
    "**V = (C<sub>1</sub> C<sub>2</sub> ... C<sub>n</sub>)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following Python code uses NumPy’s svd() function to obtain all the\n",
    " principal components of the 3D training set represented in Figure 8-2, then\n",
    " it extracts the two unit vectors that define the first two PCs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Consider Figure 8-2 from the Book Chapter: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(50)\n",
    "X = np.random.randn(1000, 3)\n",
    "X_centered = X - X.mean(axis=0)\n",
    "U, s, Vt = np.linalg.svd(X_centered)\n",
    "c1 = Vt[0]\n",
    "c2 = Vt[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **WARNING:**\n",
    " PCA assumes that the dataset is centered around the origin. As you will see, Scikit\n",
    "Learn’s PCA classes take care of centering the data for you. If you implement PCA\n",
    " yourself (as in the preceding example), or if you use other libraries, don’t forget to\n",
    " center the data first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Projecting Down to d Dimensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Once you have identified all the principal components, you can reduce the\n",
    " dimensionality of the dataset down to d dimensions by projecting it onto the\n",
    " hyperplane defined by the first d principal components. Selecting this\n",
    " hyperplane ensures that the projection will preserve as much variance as\n",
    " possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To project the training set onto the hyperplane and obtain a reduced dataset\n",
    " **X**<sub>*d-proj*</sub> of dimensionality *d*, compute the matrix multiplication of the training set matrix **X** by the matrix **W**<sub>*d*</sub>, defined as the matrix containing the first *d* columns of **V**, as shown in Equation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ***Equation: Prijecting the training set down to d dimensions***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X**<sub>*d-proj*</sub> = **XW**<sub>*d*</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Python code projects the training set onto the plane defined\n",
    " by the first two principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Vt[:2].T\n",
    "X2D = X_centered @ W2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There you have it! You now know how to reduce the dimensionality of any\n",
    " dataset by projecting it down to any number of dimensions, while\n",
    " preserving as much variance as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using Scikit-Learn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Scikit-Learn’s PCA class uses SVD to implement PCA, just like we did\n",
    " earlier in this chapter. The following code applies PCA to reduce the\n",
    " dimensionality of the dataset down to two dimensions (note that it\n",
    " automatically takes care of centering the data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25416046,  0.6020987 ,  0.75688811],\n",
       "       [ 0.33501973,  0.78894429, -0.51510066]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X2D = pca.fit_transform(X)\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the PCA transformer to the dataset, its *components_* attribute holds the transpose of **W**<sub>d</sub>: it contains one row for each of the forst *d* principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explained Variance Ratio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful piece of information is the *explained variance ratio* of each principal component, available via the ***explained_variance_ratio_*** variable. the ratio indicates the proportion of the dataset's variance that lies along each principal component. For example, let's look at the explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.340847  , 0.33605382])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output tells us that about 34% of the dataset's variance lies along the first PC, and about 34% lies along the second PC. This leaves about 32% for the third PC, so its reasonable to assume that the third PC probably carries equally information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Choosing the Right Number of Dimensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Instead of arbitrarily choosing the number of dimensions to reduce down to,\n",
    " it is simpler to choose the number of dimensions that add up to a\n",
    " sufficiently large portion of the variance—say, 95% (An exception to this\n",
    " rule, of course, is if you are reducing dimensionality for data visualization,\n",
    " in which case you will want to reduce the dimensionality down to 2 or 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following code loads and splits the MNIST dataset (introduced in\n",
    " Chapter 3) and performs PCA without reducing dimensionality, then\n",
    " computes the minimum number of dimensions required to preserve 95% of\n",
    " the training set’s variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml(\"mnist_784\", as_frame=False)\n",
    "x_train, y_train = mnist.data[:60_000], mnist.target[:60_000]\n",
    "x_test, y_test = mnist.data[60_000:], mnist.target[60_000:]\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(x_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1 # d equals to 154"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could then set n_components=d and run PCA again, but there’s a\n",
    " better option. Instead of specifying the number of principal components you\n",
    " want to preserve, you can set n_components to be a float between 0.0\n",
    " and 1.0, indicating the ratio of variance you wish to preserve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "x_reduced =pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The actual number of components is determined during training, and it is\n",
    " stored in the n_components_ attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Yet another option is to plot the explained variance as a function of the\n",
    " number of dimensions. There will\n",
    " usually be an elbow in the curve, where the explained variance stops\n",
    " growing fast. In this case, you can see that reducing the dimensionality\n",
    " down to about 100 dimensions wouldn’t lose too much explained variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Explained Variance')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cumsum, label='Elbow')\n",
    "plt.xlabel(\"Dimensions\", fontsize=14, color='indigo', fontweight='bold')\n",
    "plt.ylabel(\"Explained Variance\", fontsize=14, color='indigo', fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lastly, if you are using dimensionality reduction as a preprocessing step for\n",
    " a supervised learning task (e.g., classification), then you can tune the\n",
    " number of dimensions as you would any other hyperparameter (see\n",
    " Chapter 2). For example, the following code example creates a two-step\n",
    " pipeline, first reducing dimensionality using PCA, then classifying using a\n",
    " random forest. Next, it uses RandomizedSearchCV to find a good\n",
    " combination of hyperparameters for both PCA and the random forest\n",
    " classifier. This example does a quick search, tuning only 2 hyperparameters,\n",
    " training on just 1,000 instances, and running for just 10 iterations, but feel\n",
    " free to do a more thorough search if you have the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA(random_state=50)),\n",
       "                                             (&#x27;randomforestclassifier&#x27;,\n",
       "                                              RandomForestClassifier(random_state=50))]),\n",
       "                   param_distributions={&#x27;pca__n_components&#x27;: array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       6...\n",
       "       414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "       427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "       440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
       "       453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "       466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "       479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "       492, 493, 494, 495, 496, 497, 498, 499])},\n",
       "                   random_state=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA(random_state=50)),\n",
       "                                             (&#x27;randomforestclassifier&#x27;,\n",
       "                                              RandomForestClassifier(random_state=50))]),\n",
       "                   param_distributions={&#x27;pca__n_components&#x27;: array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       6...\n",
       "       414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "       427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "       440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
       "       453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "       466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "       479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "       492, 493, 494, 495, 496, 497, 498, 499])},\n",
       "                   random_state=50)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(random_state=50)),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(random_state=50))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(random_state=50)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=50)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('pca', PCA(random_state=50)),\n",
       "                                             ('randomforestclassifier',\n",
       "                                              RandomForestClassifier(random_state=50))]),\n",
       "                   param_distributions={'pca__n_components': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       6...\n",
       "       414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "       427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "       440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
       "       453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "       466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "       479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "       492, 493, 494, 495, 496, 497, 498, 499])},\n",
       "                   random_state=50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = make_pipeline(PCA(random_state=50),\n",
    "                    RandomForestClassifier(random_state=50))\n",
    "param_distrib = {\n",
    "    \"pca__n_components\": np.arange(10, 80), \n",
    "    \"randomforestclassifier__n_estimators\": np.arange(50, 500)\n",
    "    }\n",
    "rnd_search = RandomizedSearchCV(clf, param_distrib, n_iter=10, cv=3, random_state=50)\n",
    "rnd_search.fit(x_train[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': 212, 'pca__n_components': 28}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Let's look at the best hyperparameters found:\"\"\"\n",
    "print(rnd_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It’s interesting to note how low the optimal number of components is: we\n",
    " reduced a 784-dimensional dataset to just 28 dimensions! This is tied to the\n",
    " fact that we used a random forest, which is a pretty powerful model. If we\n",
    " used a linear model instead, such as an SGDClassifier, the search\n",
    " would find that we need to preserve more dimensions (about 69)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CONTENTS\\APPLICATIONS\\New Folder\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\CONTENTS\\APPLICATIONS\\New Folder\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\CONTENTS\\APPLICATIONS\\New Folder\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\CONTENTS\\APPLICATIONS\\New Folder\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\CONTENTS\\APPLICATIONS\\New Folder\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\CONTENTS\\APPLICATIONS\\New Folder\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\CONTENTS\\APPLICATIONS\\New Folder\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA(random_state=50)),\n",
       "                                             (&#x27;sgdclassifier&#x27;,\n",
       "                                              SGDClassifier(random_state=50))]),\n",
       "                   param_distributions={&#x27;pca__n_components&#x27;: array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       61, 62, 63, 64, 65, 66, 6...\n",
       "       414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "       427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "       440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
       "       453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "       466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "       479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "       492, 493, 494, 495, 496, 497, 498, 499])},\n",
       "                   random_state=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;pca&#x27;, PCA(random_state=50)),\n",
       "                                             (&#x27;sgdclassifier&#x27;,\n",
       "                                              SGDClassifier(random_state=50))]),\n",
       "                   param_distributions={&#x27;pca__n_components&#x27;: array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       61, 62, 63, 64, 65, 66, 6...\n",
       "       414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "       427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "       440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
       "       453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "       466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "       479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "       492, 493, 494, 495, 496, 497, 498, 499])},\n",
       "                   random_state=50)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(random_state=50)),\n",
       "                (&#x27;sgdclassifier&#x27;, SGDClassifier(random_state=50))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(random_state=50)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(random_state=50)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('pca', PCA(random_state=50)),\n",
       "                                             ('sgdclassifier',\n",
       "                                              SGDClassifier(random_state=50))]),\n",
       "                   param_distributions={'pca__n_components': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       61, 62, 63, 64, 65, 66, 6...\n",
       "       414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "       427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "       440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
       "       453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "       466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "       479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "       492, 493, 494, 495, 496, 497, 498, 499])},\n",
       "                   random_state=50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = make_pipeline(PCA(random_state=50),\n",
    "                    SGDClassifier(random_state=50))\n",
    "param_distrib = {\n",
    "    \"pca__n_components\": np.arange(10, 80), \n",
    "    \"sgdclassifier__max_iter\": np.arange(50, 500)\n",
    "    }\n",
    "rnd_search = RandomizedSearchCV(clf, param_distrib, n_iter=10, cv=3, random_state=50)\n",
    "rnd_search.fit(x_train[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sgdclassifier__max_iter': 90, 'pca__n_components': 69}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Let's look at the best hyperparameters found:\"\"\"\n",
    "print(rnd_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PCA for Compression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After dimensionality reduction, the training set takes up much less space.\n",
    " For example, after applying PCA to the MNIST dataset while preserving\n",
    " 95% of its variance, we are left with 154 features, instead of the original\n",
    " 784 features. So the dataset is now less than 20% of its original size, and we\n",
    " only lost 5% of its variance! This is a reasonable compression ratio, and it’s\n",
    " easy to see how such a size reduction would speed up a classification\n",
    " algorithm tremendously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is also possible to decompress the reduced dataset back to 784\n",
    " dimensions by applying the inverse transformation of the PCA projection.\n",
    " This won’t give you back the original data, since the projection lost a bit of\n",
    " information (within the 5% variance that was dropped), but it will likely be\n",
    " close to the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared distance between the original\n",
    " data and the reconstructed data (compressed and then decompressed) is\n",
    " called the ***reconstruction error***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The *inverse_transform()* method lets us decompress the reduced\n",
    " MNIST dataset back to 784 dimensions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recovered = pca.inverse_transform(x_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### ***Consider an example from the book....***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Equation:** ***PCA inverse transformation, back to the original of dimensions.***\n",
    "**X**<sub>recovered</sub> = **X**<sub>d-drop</sub>**W**<sub>d</sub><sup>T</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Randomized PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If you set the *svd_solver* hyperparameter to \"*randomized*\", Scikit\n",
    "Learn uses a stochastic algorithm called ***randomized PCA*** that quickly finds\n",
    " an approximation of the first d principal components. Its computational\n",
    " complexity is O(m × d<sup>2</sup>) + O(d<sup>3</sup>), instead of O(m × n<sup>2</sup>) + O(n<sup>3</sup>) for the full\n",
    " SVD approach, so it is dramatically faster than full SVD when d is much\n",
    " smaller than n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_pca = PCA(n_components=154, svd_solver='randomized', random_state=50)\n",
    "x_reduced = rnd_pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### **TIP:**\n",
    " By default, svd_solver is actually set to \"auto\": Scikit-Learn automatically uses\n",
    " the randomized PCA algorithm if max(m, n) > 500 and n_components is an integer\n",
    " smaller than 80% of min(m, n), or else it uses the full SVD approach. So the preceding\n",
    " code would use the randomized PCA algorithm even if you removed the\n",
    " svd_solver=\"randomized\" argument, since 154 < 0.8 × 784. If you want to force\n",
    " Scikit-Learn to use full SVD for a slightly more precise result, you can set the\n",
    " svd_solver hyperparameter to \"***full***\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Incremental PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " One problem with the preceding implementations of PCA is that they\n",
    " require the whole training set to fit in memory in order for the algorithm to\n",
    " run. Fortunately, incremental PCA (IPCA) algorithms have been developed\n",
    " that allow you to split the training set into mini-batches and feed these in\n",
    " one mini-batch at a time. This is useful for large training sets and for\n",
    " applying PCA online (i.e., on the fly, as new instances arrive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following code splits the MNIST training set into 100 mini-batches\n",
    " (using NumPy’s array_split() function) and feeds them to Scikit\n",
    "Learn’s IncrementalPCA class  to reduce the dimensionality of the\n",
    " MNIST dataset down to 154 dimensions, just like before. Note that you\n",
    " must call the partial_fit() method with each mini-batch, rather than\n",
    " the fit() method with the whole training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=154)\n",
    "for x_batch in np.array_split(x_train, n_batches):\n",
    "    inc_pca.partial_fit(x_batch)\n",
    "    \n",
    "x_reduced = inc_pca.transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use NumPy’s memmap class, which allows you to\n",
    " manipulate a large array stored in a binary file on disk as if it were entirely\n",
    " in memory; the class loads only the data it needs in memory, when it needs\n",
    " it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this, let’s first create a memory-mapped (memmap) file\n",
    " and copy the MNIST training set to it, then call flush() to ensure that\n",
    " any data still in the cache gets saved to disk. In real life, X_train would\n",
    " typically not fit in memory, so you would load it chunk by chunk and save\n",
    " each chunk to the right part of the memmap array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"C:/Users/jacks/Documents/Datasets/my_mnist.mmap\"\n",
    "x_mmap = np.memmap(filename, dtype='float32', mode=\"write\", shape=x_train.shape)\n",
    "x_mmap[:] = x_train # could be a loop instead, saving the data chunk by chunk\n",
    "x_mmap.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next, we can load the memmap file and use it like a regular NumPy array.\n",
    " Let’s use the IncrementalPCA class to reduce its dimensionality. Since\n",
    " this algorithm uses only a small part of the array at any given time, memory\n",
    " usage remains under control. This makes it possible to call the usual fit()\n",
    " method instead of partial_fit(), which is quite convenient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IncrementalPCA(batch_size=600, n_components=154)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;IncrementalPCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.IncrementalPCA.html\">?<span>Documentation for IncrementalPCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>IncrementalPCA(batch_size=600, n_components=154)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "IncrementalPCA(batch_size=600, n_components=154)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mmap = np.memmap(filename, dtype='float32', mode='readonly').reshape(-1, 784)\n",
    "batch_size = x_mmap.shape[0] // n_batches\n",
    "inc_pca = IncrementalPCA(n_components=154, batch_size=batch_size)\n",
    "inc_pca.fit(x_mmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### WARNING:\n",
    "Only the raw binary data is saved to disk, so you need to specify the data type and shapeof the array when you load it. If you omit the shape, *np.memmap()* returns a 1D array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For very high-dimensional datasets, PCA can be too slow. As you saw\n",
    " earlier, even if you use randomized PCA its computational complexity is\n",
    " still O(m × d<sup>2</sup>) + O(d<sup>3</sup>), so the target number of dimensions d must not be\n",
    " 3\n",
    "too large. If you are dealing with a dataset with tens of thousands of\n",
    " features or more (e.g., images), then training may become much too slow:\n",
    " in this case, you should consider using random projection instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Projection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As its name suggests, the random projection algorithm projects the data to a\n",
    " lower-dimensional space using a random linear projection. This may sound\n",
    " crazy, but it turns out that such a random projection is actually very likely to\n",
    " preserve distances fairly well, as was demonstrated mathematically by\n",
    " William B. Johnson and Joram Lindenstrauss in a famous lemma. So, two\n",
    " similar instances will remain similar after the projection, and two very\n",
    " different instances will remain very different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the more dimensions you drop, the more information is lost, and\n",
    " the more distances get distorted. So how can you choose the optimal\n",
    " number of dimensions? Well, Johnson and Lindenstrauss came up with an\n",
    " equation that determines the minimum number of dimensions to preserve in\n",
    " order to ensure—with high probability—that distances won’t change by\n",
    " more than a given tolerance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For example, if you have a dataset containing\n",
    " m = 5,000 instances with n = 20,000 features each, and you don’t want the\n",
    " squared distance between any two instances to change by more than ε =\n",
    " 10%, then you should project the data down to d dimensions, with ***d ≥ 4log(m) / (½ ε² - ⅓ ε³)***, which is 7,300 dimensions. That’s quite a significant\n",
    " dimensionality reduction! Notice that the equation does not use n, it only\n",
    " relies on m and ε. This equation is implemented by the\n",
    " *johnson_lindenstrauss_min_dim()* function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7300"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "\n",
    "m, ε = 5_000, 0.1\n",
    "d = johnson_lindenstrauss_min_dim(m, eps=ε)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can just generate a random matrix P of shape [d, n], where each\n",
    " item is sampled randomly from a Gaussian distribution with mean 0 and\n",
    " variance 1 / d, and use it to project a dataset from n dimensions down to d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20_000\n",
    "np.random.seed(50)\n",
    "p = np.random.randn(d, n) / np.sqrt(d) # std dev = square root of variance.\n",
    "\n",
    "x = np.random.randn(m, n) # generate a fake dataset\n",
    "x_reduced = x @ p.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " That’s all there is to it! It’s simple and efficient, and no training is required:\n",
    " the only thing the algorithm needs to create the random matrix is the\n",
    " dataset’s shape. The data itself is not used at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Scikit-Learn offers a GaussianRandomProjection class to do exactly\n",
    " what we just did: when you call its fit() method, it uses\n",
    " johnson_lindenstrauss_min_dim() to determine the output\n",
    " dimensionality, then it generates a random matrix, which it stores in the\n",
    " components_ attribute. Then when you call transform(), it uses this\n",
    " matrix to perform the projection. When creating the transformer, you can\n",
    " set eps if you want to tweak ε (it defaults to 0.1), and n_components if\n",
    " you want to force a specific target dimensionality d. The following code\n",
    " example gives the same result as the preceding code (you can also verify\n",
    " that gaussian_rnd_proj.components_ is equal to P):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7300"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "gaussian_rnd_proj = GaussianRandomProjection(eps=ε, random_state=50)\n",
    "x_reduced = gaussian_rnd_proj.fit_transform(x) # same result  as above.\n",
    "len(gaussian_rnd_proj.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Scikit-Learn also provides a second random projection transformer, known\n",
    " as SparseRandomProjection. It determines the target dimensionality\n",
    " in the same way, generates a random matrix of the same shape, and\n",
    " performs the projection identically. The main difference is that the random\n",
    "matrix is sparse. This means it uses much less memory: about 25 MB\n",
    " instead of almost 1.2 GB in the preceding example! And it’s also much\n",
    " faster, both to generate the random matrix and to reduce dimensionality:\n",
    " about 50% faster in this case. Moreover, if the input is sparse, the\n",
    " transformation keeps it sparse (unless you set dense_output=True)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lastly, it enjoys the same distance-preserving property as the previous\n",
    " approach, and the quality of the dimensionality reduction is comparable. In\n",
    " short, it’s usually preferable to use this transformer instead of the first one,\n",
    " especially for large or sparse datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The ratio r of nonzero items in the sparse random matrix is called its\n",
    " density. By default, it is equal to \n",
    "1/√\n",
    " n\n",
    " . With 20,000 features, this means\n",
    " that only 1 in ~141 cells in the random matrix is nonzero: that’s quite\n",
    " sparse! You can set the density hyperparameter to another value if you\n",
    " prefer. Each cell in the sparse random matrix has a probability r of being\n",
    " nonzero, and each nonzero value is either –v or +v (both equally likely),\n",
    " where v = 1/√dr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If you want to perform the inverse transform, you first need to compute the\n",
    " pseudo-inverse of the components matrix using SciPy’s pinv() function,\n",
    " then multiply the reduced data by the transpose of the pseudo-inverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_pinv = np.linalg.pinv(gaussian_rnd_proj.components_)\n",
    "x_recovered = x_reduced @ components_pinv.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **WARNING:**\n",
    " Computing the pseudo-inverse may take a very long time if the components matrix is\n",
    " large, as the computational complexity of pinv() is O(dn²) if d < n, or O(nd²)\n",
    " otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In summary, random projection is a simple, fast, memory-efficient, and\n",
    " surprisingly powerful dimensionality reduction algorithm that you should\n",
    " keep in mind, especially when you deal with high-dimensional datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **NOTE:**\n",
    " Random projection is not always used to reduce the dimensionality of large datasets. For\n",
    " example, a 2017 paper  by Sanjoy Dasgupta et al. showed that the brain of a fruit fly\n",
    " implements an analog of random projection to map dense low-dimensional olfactory\n",
    " inputs to sparse high-dimensional binary outputs: for each odor, only a small fraction of\n",
    " the output neurons get activated, but similar odors activate many of the same neurons.\n",
    " This is similar to a well-known algorithm called locality sensitive hashing (LSH), which\n",
    " is typically used in search engines to group similar documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***Locally linear embedding (LLE)***  is a nonlinear dimensionality reduction\n",
    " (NLDR) technique. It is a manifold learning technique that does not rely on\n",
    " projections, unlike PCA and random projection. In a nutshell, LLE works\n",
    " by first measuring how each training instance linearly relates to its nearest\n",
    " neighbors, and then looking for a low-dimensional representation of the\n",
    " training set where these local relationships are best preserved (more details\n",
    " shortly). This approach makes it particularly good at unrolling twisted\n",
    " manifolds, especially when there is not too much noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following code makes a Swiss roll, then uses Scikit-Learn’s\n",
    " LocallyLinearEmbedding class to unroll it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "x_swiss, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=50)\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10, random_state=50)\n",
    "x_unrolled = lle.fit_transform(x_swiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The variable t is a 1D NumPy array containing the position of each\n",
    " instance along the rolled axis of the Swiss roll. We don’t use it in this\n",
    " example, but it can be used as a target for a nonlinear regression task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting 2D dataset.The Swissroll is completely unrolled, and the distances between instances are locally\n",
    " well preserved. However, distances are not preserved on a larger scale: the\n",
    " unrolled Swiss roll should be a rectangle, not this kind of stretched and\n",
    " twisted band. Nevertheless, LLE did a pretty good job of modeling the\n",
    " manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here’s how LLE works: for each training instance x<sup>(i)</sup> , the algorithm\n",
    " identifies its k-nearest neighbors (in the preceding code k = 10), then tries to\n",
    " reconstruct x<sup>(i)</sup> as a linear function of these neighbors. More specifically, it tries to find the weights w<sub>*i,j*</sub> such that the squared distance between x<sup>(i)</sup> and ***∑<sup>m</sup><sub>j=1</sub> w<sub>i,j</sub>X<sup>(i)</sup>***\n",
    " is as small as possible, assuming w<sub>i,j</sub> = 0 if **x**<sup>(i)</sup> is not one of\n",
    " the k-nearest neighbors of **x**<sup>(i)</sup> .Thus the first step of LLE is the constrained\n",
    " optimization problem described in Equation below, where **W** is the weight\n",
    " matrix containing all the weights w<sub>i,j</sub> . The second constraint simply\n",
    " normalizes the weights for each training instance x<sup>(i)</sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### **Equation: ***LLE step1, linear modeling local ralationships***\n",
    "**W** = argmin<sub>w</sub> ∑<sup>m</sup><sub>i=1</sub> ( **X**<sup>(i)</sup> - ∑<sup>m</sup><sub>j=1</sub>*w*<sub>i,j</sub>**X**<sup>(j)</sup>)<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step the weight matrix **W** (Containing the weights w<sub>i,j</sub>)encodes\n",
    " the local linear relationships between the training instances. The second\n",
    " step is to map the training instances into a d-dimensional space (where d <\n",
    " n) while preserving these local relationships as much as possible. If **Z**<sup>(i)</sup> is the image of **X**<sup>(i)</sup> inthis d-dimensional space, then we want the squared distance between **Z**<sup>(i)</sup> and ∑<sup>m</sup><sub>j=1</sub> w<sub>i,j</sub>**Z**<sup>(j)</sup> to be as small as possible. This idea leads to the unconstrained optimization problem discribed in the below Equation.  It looks very similar to the first step, but instead of keeping the instances\n",
    " fixed and finding the optimal weights, we are doing the reverse: keeping the\n",
    " weights fixed and finding the optimal position of the instances’ images in\n",
    " the low-dimensional space. Note that **Z** is the matrix containing all **z**<sub>(i)</sub>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### ***Equation: LLE step 2,  reducing dimensionality while preserving relationships***\n",
    "> **Z** = argmin<sub>**z**</sub> **∑**<sup>*m*</sup><sub>*i=1*</sub> ( **Z**<sup>*(i)</sup> - **∑**<sup>*m*</sup><sub>*j=1*</sub> *w<sub>i,j</sub>**Z**<sup>*(j)</sup>*)<SUP>2</SUP>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Scikit-Learn’s LLE implementation has the following computational\n",
    " complexity: O(m log(m)n log(k)) for finding the k-nearest neighbors,\n",
    " O(mnk<sup>3</sup>) for optimizing the weights, and O(dm<sup>2</sup>) for constructing the low\n",
    "dimensional representations. Unfortunately, the m<sup>2</sup> in the last term makes\n",
    " this algorithm scale poorly to very large datasets.\n",
    " As you can see, LLE is quite different from the projection techniques, and\n",
    " it’s significantly more complex, but it can also construct much better low\n",
    "dimensional representations, especially if the data is nonlinear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Other Dimensionality Reduction Techniques**\n",
    " Before we conclude this chapter, let’s take a quick look at a few other\n",
    " popular dimensionality reduction techniques available in Scikit-Learn:\n",
    " - ***sklearn.manifold.MDS***\n",
    "Multidimensional scaling (MDS) reduces dimensionality while trying to preserve the distance between the instances. Random projection does that for high-dimensional data, but it doesn't work well on low-dimensional data.\n",
    "\n",
    "- ***sklearn.manifold.isomap***\n",
    "Isomap creates a graph by connecting each instance to its nearest\n",
    "neighbors, then reduces dimensionality while trying to preserve the\n",
    "geodesic distances between the instances. The geodesic distance\n",
    "between two nodes in a graph is the number of nodes on the shortest\n",
    "path between these nodes.\n",
    "\n",
    "- ***sklearn.manifold.TSNE***\n",
    "   t-distributed stochastic neighbor embedding (t-SNE) reduces\n",
    " dimensionality while trying to keep similar instances close and\n",
    " dissimilar instances apart. It is mostly used for visualization, in\n",
    " particular to visualize clusters of instances in high-dimensional space.\n",
    " For example, in the exercises at the end of this chapter you will use t\n",
    "SNE to visualize a 2D map of the MNIST images.\n",
    "\n",
    "- ***sklearn.discriminant_analysis.LinearDiscriminantAnalysis***\n",
    "   Linear discriminant analysis (LDA) is a linear classification algorithm\n",
    " that, during training, learns the most discriminative axes between the\n",
    " classes. These axes can then be used to define a hyperplane onto which\n",
    " to project the data. The benefit of this approach is that the projection\n",
    " will keep classes as far apart as possible, so LDA is a good technique to\n",
    "reduce dimensionality before running another classification algorithm\n",
    " (unless LDA alone is sufficient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EXERCISE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
